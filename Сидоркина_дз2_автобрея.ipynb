{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZSptU56JQCe"
      },
      "source": [
        "#pip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15.0 simple_elmo -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKQuF8e950SR",
        "outputId": "6318a73e-5158-4992-e7fe-091e83427ca1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2fsKpDgaJPxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fbbd19-61ac-4cbe-8ded-5225957f8bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/83.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install corus -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c52MKen4JUZa"
      },
      "outputs": [],
      "source": [
        "!pip install pymystem3 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvv-RjO5wY-c",
        "outputId": "f243ee7d-704c-4876-eddf-29b968d636ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for adagram (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/lopuhin/python-adagram.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install simple-elmo -q"
      ],
      "metadata": {
        "id": "y4sJ_ZTBGAJe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNXvw4do1-LY",
        "outputId": "6a968c95-6458-47de-f463-848765b929bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib\" > /content/drive/MyDrive/all.a010.p10.d300.w5.m100.nonorm.slim.joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3NcZjxDnhyc",
        "outputId": "057d6d8b-362e-4430-d853-78087fc971f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1394M  100 1394M    0     0  32.6M      0  0:00:42  0:00:42 --:--:-- 35.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/RNC_texts.rar -q\n",
        "!unrar x RNC_texts.rar\n",
        "!rm RNC_texts.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZdSCgKSoTnk",
        "outputId": "ef64289b-02b0-4a0c-90fc-7e25bf39a511"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from RNC_texts.rar\n",
            "\n",
            "Extracting  RNCgoldInUD_Morpho.conll                                     \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/GIKRYA_texts_new.zip -q\n",
        "!unzip GIKRYA_texts_new.zip\n",
        "!rm GIKRYA_texts_new.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eeHkPex8SCn",
        "outputId": "c9572a93-6752-43d9-da97-9c11ff609745"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  GIKRYA_texts_new.zip\n",
            "  inflating: gikrya_new_test.out     \n",
            "  inflating: gikrya_new_train.out    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/dialogue-evaluation/morphoRuEval-2017/raw/master/OpenCorpora_Texts.rar -q\n",
        "!unrar x OpenCorpora_Texts.rar\n",
        "!rm OpenCorpora_Texts.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCCFc6jd8Wu6",
        "outputId": "74ea7e33-905a-430f-8d5f-3db65e2532ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from OpenCorpora_Texts.rar\n",
            "\n",
            "Extracting  unamb_sent_14_6.conllu                                       \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vectors.nlpl.eu/repository/20/196.zip -q\n",
        "!unzip 196.zip -d 196"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRaFmmLOrUwD",
        "outputId": "0086b457-2dd2-4d91-c233-cd06fd1d20c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  196.zip\n",
            "  inflating: 196/meta.json           \n",
            "  inflating: 196/model.hdf5          \n",
            "  inflating: 196/options.json        \n",
            "  inflating: 196/README              \n",
            "  inflating: 196/vocab.txt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from pymystem3 import Mystem\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "from corus import load_morphoru_rnc\n",
        "from corus import load_morphoru_gicrya\n",
        "from corus import load_gramru\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "import adagram\n",
        "from simple_elmo import ElmoModel\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import requests\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "f2HcNKt9nIsA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoMQ9nfps5f2"
      },
      "source": [
        "#1. Сбор данных\n",
        "(1 балл за ручной сбор данных, 1 балл за краулинг) Выберите 5 неоднозначных лексем и соберите для них словарные значения (толкования). Можно использовать МАС или любой другой толковый словарь. Обязательно укажите, каким словарем вы пользовались. Советуем начать с ручного сбора данных, а затем, если останется время, сделать краулинг словаря. Так вы рискуете меньшим количеством баллов\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOLp5aQi-78X"
      },
      "source": [
        "####Ручной сбор\n",
        "Я выбрала слова замок, ключ, мир, лук, рука из словаря МАС. Привела только толкования слов, примеры использования убрала."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_list = ['замок', 'лук', 'рука', 'мир', 'ключ']"
      ],
      "metadata": {
        "id": "KdXh_fGnu0--"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xBSAIsokuhqp"
      },
      "outputs": [],
      "source": [
        "word_definitions = {\n",
        "    'замок': ['Дворец и крепость феодала.', 'Механизм для запирания дверей'],\n",
        "\n",
        "    'лук': ['Огородное растение сем. лилейных, овощ', 'Ручное оружие для метания стрел в виде дуги, стянутой тетивой'],\n",
        "\n",
        "    'рука': ['Каждая из двух верхних конечностей человека от плечевого сустава до кончиков пальцев', 'Манера письма, почерк',\n",
        "             'Употребляется в значении: работники, люди, выполняющие какую-л. работу',\n",
        "             'Употребляется для обозначения человека, который имеет власть, влияние, может оказать покровительство, содействие кому-л.'],\n",
        "\n",
        "    'мир': ['Совокупность всех форм материи в земном и космическом пространстве; Вселенная', 'Земной шар, Земля со всем существующим на ней',\n",
        "            'Согласие, отсутствие разногласий, вражды или ссоры', 'Какая-л. сфера жизни или область явлений в природе.',\n",
        "            'Отсутствие войны, вооруженных действий между государствами; согласное сосуществование государств, народов'],\n",
        "\n",
        "    'ключ': ['Металлическое приспособление для запирания и отпирания замка',\n",
        "             'Бьющий из земли источник, родник',\n",
        "             'Знак в начале нотной строки, условно указывающий на ноту, по высоте которой устанавливается высотное положение других нот (муз.)']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Краулинг"
      ],
      "metadata": {
        "id": "jlCPbZA73BeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "iI9Zy5MK54LV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crauler(word, word_definitions_cr):\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "    response = requests.get(f\"https://sinonim.org/t/{word}\", headers=headers, auth=('user', 'pass'))\n",
        "\n",
        "    text = response.text\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    defs = []\n",
        "    for p in soup.find_all('p'):\n",
        "        defs.append(p.get_text(strip=True))\n",
        "    #for defi in defs:\n",
        "    if word not in word_definitions_cr:\n",
        "        word_definitions_cr[word] = [defi.strip() for defi in defs if defi.strip()]\n",
        "    else:\n",
        "        word_definitions_cr[word].extend(defi.strip() for defi in defs if defi.strip())\n",
        "    return word_definitions_cr"
      ],
      "metadata": {
        "id": "jmVDGtWnGcSd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_definition_cr = {}\n",
        "for i in words_list:\n",
        "    word_definition_cr = crauler(i, word_definition_cr)"
      ],
      "metadata": {
        "id": "3GCjL5H99hH5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfMWekxg-6tG"
      },
      "source": [
        "#2. Извлечение предложений\n",
        "(1 балл) Выберите один или несколько корпусов коллекции Corus, извлеките оттуда все предложения, где содержатся ваши неоднозначные слова. Лучше провести лемматизацию с помощью хорошей библиотеки (не pymorphy), чтобы учесь формы слова.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = {}"
      ],
      "metadata": {
        "id": "U9kHTrh4nNQ7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences(records):\n",
        "    for record in records:\n",
        "        hit = ''\n",
        "        for token in record.tokens:\n",
        "            if token.lemma in words_list:\n",
        "                hit = token.lemma\n",
        "        if hit:\n",
        "            try:\n",
        "                full_sentence = TreebankWordDetokenizer().detokenize([token.text for token in record.tokens])\n",
        "            except:\n",
        "                continue\n",
        "            sentence = []\n",
        "            for token in record.tokens:\n",
        "                if not set(token.lemma) & set(punctuation + '«»') and token.lemma:\n",
        "                    sentence.append(token.lemma)\n",
        "            if hit in sentences:\n",
        "                sentences[hit].append({'text': full_sentence, 'tokens': sentence})\n",
        "            else:\n",
        "                sentences[hit] = [{'text': full_sentence, 'tokens': sentence}]"
      ],
      "metadata": {
        "id": "Er6S4vE-mwD7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0f5zRDJLyMV0"
      },
      "outputs": [],
      "source": [
        "path_rnc = 'RNCgoldInUD_Morpho.conll'\n",
        "records_rnc = load_morphoru_rnc(path_rnc)\n",
        "get_sentences(records_rnc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_gicrya = 'gikrya_new_test.out'\n",
        "records_gicrya = load_morphoru_gicrya(path_gicrya)\n",
        "get_sentences(records_gicrya)"
      ],
      "metadata": {
        "id": "S0XZihKV86H0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_gramru = 'unamb_sent_14_6.conllu'\n",
        "records_gramru = load_gramru(path_gramru)\n",
        "get_sentences(records_gramru)"
      ],
      "metadata": {
        "id": "5EuzzLAi-SN9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdm8qiteFXUP"
      },
      "source": [
        "#3. Разбиение контекстов\n",
        "\n",
        "(2 балла) Разбейте полученные контексты по значениям двумя любыми способами (вы можете использовать способы с семинара, заменить там эмбеддинги, реализовать какой-то свой способ). Напоминалка: в случае с AdaGram вы сразу получаете какой-то номер значения, с ELMo и другими контекстуальными эмбеддингами — нужно кластеризовать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb5wkzTEvqXj"
      },
      "source": [
        "###AdaGram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "FeBZTlJuw6Xg"
      },
      "outputs": [],
      "source": [
        "vm = adagram.VectorModel.load('/content/drive/MyDrive/all.a010.p10.d300.w5.m100.nonorm.slim.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in sentences:\n",
        "    for i, sentence in enumerate(sentences[words]):\n",
        "        means = vm.disambiguate(words, sentence['tokens'])\n",
        "        val = np.argmax(means)\n",
        "        sentences[words][i]['adagram'] = val"
      ],
      "metadata": {
        "id": "743CEhhXqVeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71580d6e-f412-479d-c2f4-667a26a3403c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/adagram/model.py:171: RuntimeWarning: divide by zero encountered in log\n",
            "  z = np.log(z)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGeyH4Jtvvad"
      },
      "source": [
        "###ELMo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ElmoModel()\n",
        "model.load(\"196\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vGY6sNpcBy4e",
        "outputId": "fe24eaf4-4e72-494a-ee45-9ad115020133"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/simple_elmo/model.py:531: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  lstm_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The model is now loaded.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_elmo(word, tokens, model):\n",
        "    all_vectors = model.get_elmo_vectors(tokens)\n",
        "    word_vecs = []\n",
        "    errors = []\n",
        "    for i in range(len(tokens)):\n",
        "        try:\n",
        "            word_vecs.append(all_vectors[i][tokens[i].index(word)])\n",
        "        except ValueError:\n",
        "            errors.append(i)\n",
        "\n",
        "    #word_vecs = np.array(word_vecs)\n",
        "    #unique_word_vecs = np.unique(word_vecs, axis=0)\n",
        "    #n_clusters = min(len(unique_word_vecs), len(word_definitions[word]))\n",
        "\n",
        "    cluster = KMeans(n_clusters=len(word_definitions[word]), random_state=0, n_init='auto')\n",
        "    #cluster = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
        "    cluster.fit(word_vecs)\n",
        "    labels = cluster.labels_\n",
        "    #full_labels = np.full(len(tokens), -1)\n",
        "    #for idx in range(len(tokens)):\n",
        "    #    if idx not in errors:\n",
        "    #        full_labels[idx] = labels[idx - len(errors)]\n",
        "\n",
        "    #return full_labels\n",
        "    for i in errors:\n",
        "      labels = labels.insert(i, -1)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "xLE-UUcYtqea"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for words in sentences:\n",
        "    tkns = [d_amb['tokens'] for d_amb in sentences[words]]\n",
        "    labs = get_elmo(words, tkns, model)\n",
        "    for j, d_amb in enumerate(sentences[words]):\n",
        "        d_amb['elmo'] = labs[j]\n",
        "        sentences[words][j] = d_amb"
      ],
      "metadata": {
        "id": "I9addhgit9Hs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpPNbilndBhb"
      },
      "source": [
        "#4. Значения для словарных толкований\n",
        "\n",
        "(1 балл) Возьмите словарные толкования для каждого значения и припишите им значение автоматически теми же способами, что и в п.3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1KDZD8mjA9aC"
      },
      "outputs": [],
      "source": [
        "mystem = Mystem()\n",
        "token = RegexpTokenizer('\\w+')\n",
        "\n",
        "def normalize(text):\n",
        "    words = tokenize(text)\n",
        "    normalized_words = [mystem.lemmatize(word)[0] for word in words if word]\n",
        "    return normalized_words\n",
        "\n",
        "def tokenize(text):\n",
        "    return token.tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###AdaGram\n"
      ],
      "metadata": {
        "id": "3jA91kFPvBdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "definitions_pred = {}"
      ],
      "metadata": {
        "id": "WDrUnTYTvI7R"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_definitions:\n",
        "    definitions_pred[word] = []\n",
        "    for definition in word_definitions[word]:\n",
        "        definition_norm = normalize(definition)\n",
        "        means = vm.disambiguate(word, definition_norm)\n",
        "        val = np.argmax(means)\n",
        "        definitions_pred[word].append({'def': definition, 'adagram': val})"
      ],
      "metadata": {
        "id": "Vj-kUur9u4Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece90c19-4cc3-45fe-93b0-5728d255f25c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/adagram/model.py:171: RuntimeWarning: divide by zero encountered in log\n",
            "  z = np.log(z)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ELMo"
      ],
      "metadata": {
        "id": "8tGnFOGJvoEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_definitions:\n",
        "    tkns = [normalize(definition) for definition in word_definitions[word]]\n",
        "    for i, tkn in enumerate(tkns):\n",
        "        tkn.insert(0, word)\n",
        "        tkns[i] = tkn\n",
        "    lbls = get_elmo(word, tkns, model)\n",
        "    for j, dct in enumerate(definitions_pred[word]):\n",
        "        dct['elmo'] = lbls[j]\n",
        "        definitions_pred[word][j] = dct"
      ],
      "metadata": {
        "id": "Zo7r3UtivrBA"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wYX3hw7MC-c"
      },
      "source": [
        "#5. Тестовый корпус\n",
        "\n",
        "(1 балл) Создайте тестовый корпус для ваших данных: выберите по 2-3 значения для слова и по 5 контекстов, которые автоматически были отнесены к этим значениям. Разметьте контексты: совпадает ли значение слова в контексте со словарным значением."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in sentences:\n",
        "    dict_1 = random.choice(definitions_pred[words])\n",
        "    dict_2 = random.choice(definitions_pred[words])\n",
        "    while dict_2 == dict_1:\n",
        "        dict_2 = random.choice(definitions_pred[words])\n",
        "\n",
        "    adagram1 = [word_dict for word_dict in sentences[words] if word_dict['adagram'] == dict_1['adagram']][:5]\n",
        "    elmo1 = [word_dict for word_dict in sentences[words] if word_dict['elmo'] == dict_1['elmo']][:5]\n",
        "    adagram2 = [word_dict for word_dict in sentences[words] if word_dict['adagram'] == dict_2['adagram']][:5]\n",
        "    elmo2 = [word_dict for word_dict in sentences[words] if word_dict['elmo'] == dict_2['elmo']][:5]\n",
        "\n",
        "    print(f\"Word: {words}\")\n",
        "\n",
        "    print('Definition:', dict_1['def'])\\\n",
        "\n",
        "    print(f'AdaGram ({dict_1[\"adagram\"]})')\n",
        "    for i, dct in enumerate(adagram1):\n",
        "        print(f\"{i + 1}. {dct['text']}\")\n",
        "\n",
        "    print(f'ELMo ({dict_1[\"elmo\"]})')\n",
        "    for i, dct in enumerate(elmo1):\n",
        "        print(f\"{i + 1}. {dct['text']}\")\n",
        "\n",
        "    print('Definition:', dict_2['def'])\n",
        "\n",
        "    print(f'AdaGram ({dict_2[\"adagram\"]})')\n",
        "    for i, dct in enumerate(adagram2):\n",
        "        print(f\"{i + 1}. {dct['text']}\")\n",
        "\n",
        "    print(f'ELMo ({dict_2[\"elmo\"]})')\n",
        "    for i, dct in enumerate(elmo2):\n",
        "        print(f\"{i + 1}. {dct['text']}\")"
      ],
      "metadata": {
        "id": "xYg1kOuj8AXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjYooyGIJAdY"
      },
      "source": [
        "#6. Accuracy\n",
        "(1 балл) Оцените accuracy — в какой доле контекстов автоматически определенно значение для контекста совпадает с автоматически определенным значением толкования."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "тут разобрала тестовый корпус https://docs.google.com/document/d/1j_eDcPXi-WtPLJzBJI66fBBTmf_7Ny9vxUavTuFmVm8/edit?usp=sharing"
      ],
      "metadata": {
        "id": "04XMnBpzylgq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rvgFjkCPJA3g"
      },
      "outputs": [],
      "source": [
        "wrong_def_adagram = 16\n",
        "total_adagram = 45\n",
        "wrong_def_elmo = 34\n",
        "total_elmo = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_adagram = (total_adagram - wrong_def_adagram) / total_adagram\n",
        "print(f\"Accuracy AdaGram: \", accuracy_adagram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGKIvPdsz0dj",
        "outputId": "a826bdbd-6c75-478d-e534-62ad3eebb32a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy AdaGram:  0.6444444444444445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_elmo = (total_elmo - wrong_def_elmo) / total_elmo\n",
        "print(f\"Accuracy ELMo: \", accuracy_elmo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqjnGGsL0Ild",
        "outputId": "c2cde4f4-24bc-4859-f583-dd790c0dcdd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy ELMo:  0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Анализ ошибок\n",
        "\n",
        "(2 балла) Проведите анализ ошибок. Сравните результаты двух методов WSD, объясните, почему результаты совпадают или расходятся (и покажите на конкретных примерах)"
      ],
      "metadata": {
        "id": "qJuMpuW4R8xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ELMo использует фиксированные слои LSTM и не всегда улавливает сложные зависимости между словами. AdaGram адаптирует представления слов в зависимости от конкретного контекста, поэтому показывает точность в 2 раза выше, чем у ELMo.\n",
        "\n",
        "\n",
        "ELMo либо редко попадает в значение, либо не попадает вообще. Забавно, что обеим моделям трудно дались определения слов \"мир\" и \"рука\". Прикольно вышло, что AdaGram смог привести только 1 правильный пример значения \"ключ - источник, родник\", а ELMo привел 5, но все неправильные... Такое же случилось со словом \"замок - крупость\": у первом модели 4 примера, но все правильные, а у второй 5 примеров, но правильный 1...\n",
        "\n",
        "\n",
        "Была проблема, когда обе модели могли предложить короткое предложение с выбранными мной словами, но для понимания, правильное ли значение у этого слова, не хватало контекста. Таких случаев немного, поэтому я снисходительно относилась к моделям и не вычеркивала пример из правильных. ELMo: 1. А увидят замок--и развернутся. AdaGram: 5. Я вот у тебя взяла тогда лук.\n",
        "\n",
        "Следующая проблема.\n",
        "\n",
        "\"Definition: Совокупность всех форм материи в земном и космическом пространстве; Вселенная\n",
        "AdaGram (2)\n",
        "1. Порок и разврат правят миром ...\n",
        "2. Краткие содержания спасут мир)\n",
        "3. У меня свои методы борьбы с ее представлением о своей власти над миром))\"\n",
        "\n",
        "Казалось бы, у меня был вариант определения мир - Земля и всё на Земле. Однако, в целом, примеры-то могут подойти по смыслу. Так что даже не знаю, что с этим делать.\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "g6j-47zY0u47"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CZSptU56JQCe",
        "FoMQ9nfps5f2",
        "kE4WD7sGFJO7",
        "GGeyH4Jtvvad",
        "tpPNbilndBhb",
        "9wYX3hw7MC-c"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
